"""
âš™ï¸ CAACé¡¹ç›®é«˜çº§é…ç½®ç¤ºä¾‹

æœ¬æ–‡ä»¶å±•ç¤ºCAACé¡¹ç›®çš„é«˜çº§é…ç½®é€‰é¡¹ï¼ŒåŒ…æ‹¬ï¼š
- é…ç½®æ–‡ä»¶ç®¡ç†
- åŠ¨æ€å‚æ•°è°ƒæ•´
- æ€§èƒ½ä¼˜åŒ–é…ç½®
- å®éªŒé…ç½®æ¨¡æ¿

è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼špython examples/advanced_config.py
"""

import sys
import os
import json
import yaml
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.models.caac_ovr_model import CAACOvRModel
from src.experiments.experiment_manager import ExperimentManager
from sklearn.datasets import load_digits, load_wine
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt


class ConfigurationManager:
    """
    é«˜çº§é…ç½®ç®¡ç†å™¨
    """
    
    def __init__(self, config_dir="examples/configs"):
        self.config_dir = Path(config_dir)
        self.config_dir.mkdir(exist_ok=True)
        
    def create_default_configs(self):
        """
        åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
        """
        print("=" * 60)
        print("âš™ï¸ åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶")
        print("=" * 60)
        
        configs = {
            # æ¨¡å‹é…ç½®
            'model_configs': {
                'small_dataset': {
                    'representation_dim': 32,
                    'latent_dim': 16,
                    'feature_hidden_dims': [32],
                    'abduction_hidden_dims': [32, 16],
                    'lr': 0.01,
                    'batch_size': 16,
                    'epochs': 100,
                    'early_stopping_patience': 10,
                    'learnable_thresholds': False,
                    'uniqueness_constraint': False
                },
                'medium_dataset': {
                    'representation_dim': 64,
                    'latent_dim': 32,
                    'feature_hidden_dims': [128, 64],
                    'abduction_hidden_dims': [64, 32],
                    'lr': 0.001,
                    'batch_size': 32,
                    'epochs': 150,
                    'early_stopping_patience': 15,
                    'learnable_thresholds': True,
                    'uniqueness_constraint': False
                },
                'large_dataset': {
                    'representation_dim': 128,
                    'latent_dim': 64,
                    'feature_hidden_dims': [256, 128],
                    'abduction_hidden_dims': [128, 64],
                    'lr': 0.001,
                    'batch_size': 64,
                    'epochs': 200,
                    'early_stopping_patience': 20,
                    'learnable_thresholds': True,
                    'uniqueness_constraint': True,
                    'uniqueness_weight': 0.1
                },
                'robust_model': {
                    'representation_dim': 64,
                    'latent_dim': 32,
                    'feature_hidden_dims': [128, 64],
                    'abduction_hidden_dims': [64, 32],
                    'lr': 0.001,
                    'batch_size': 32,
                    'epochs': 200,
                    'early_stopping_patience': 25,
                    'learnable_thresholds': True,
                    'uniqueness_constraint': True,
                    'uniqueness_weight': 0.15,
                    'uniqueness_samples': 15
                }
            },
            
            # å®éªŒé…ç½®
            'experiment_configs': {
                'quick_test': {
                    'datasets': ['iris', 'wine'],
                    'noise_levels': [0.0, 0.1, 0.2],
                    'test_size': 0.3,
                    'n_runs': 3,
                    'save_plots': True,
                    'save_detailed_results': False
                },
                'standard_robustness': {
                    'datasets': ['iris', 'wine', 'breast_cancer', 'digits'],
                    'noise_levels': [0.0, 0.05, 0.1, 0.15, 0.2],
                    'test_size': 0.3,
                    'n_runs': 5,
                    'save_plots': True,
                    'save_detailed_results': True
                },
                'comprehensive_evaluation': {
                    'datasets': ['iris', 'wine', 'breast_cancer', 'optical_digits', 
                               'digits', 'synthetic_imbalanced'],
                    'noise_levels': [0.0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],
                    'test_size': 0.2,
                    'n_runs': 10,
                    'save_plots': True,
                    'save_detailed_results': True,
                    'cross_validation': True,
                    'cv_folds': 5
                }
            },
            
            # æ€§èƒ½é…ç½®
            'performance_configs': {
                'debug_mode': {
                    'verbose': 2,
                    'save_intermediate_results': True,
                    'plot_training_curves': True,
                    'validate_inputs': True
                },
                'production_mode': {
                    'verbose': 1,
                    'save_intermediate_results': False,
                    'plot_training_curves': False,
                    'validate_inputs': False,
                    'use_gpu': True,
                    'parallel_experiments': True
                },
                'memory_optimized': {
                    'batch_size_multiplier': 0.5,
                    'representation_dim_multiplier': 0.75,
                    'save_models': False,
                    'early_stopping_patience_multiplier': 0.8
                }
            }
        }
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        for config_name, config_data in configs.items():
            # JSONæ ¼å¼
            json_file = self.config_dir / f"{config_name}.json"
            with open(json_file, 'w') as f:
                json.dump(config_data, f, indent=2)
            print(f"ğŸ“ åˆ›å»º {json_file}")
            
            # YAMLæ ¼å¼
            yaml_file = self.config_dir / f"{config_name}.yaml"
            with open(yaml_file, 'w') as f:
                yaml.dump(config_data, f, default_flow_style=False)
            print(f"ğŸ“ åˆ›å»º {yaml_file}")
        
        return configs
    
    def load_config(self, config_name: str, config_type: str = 'json') -> Dict[str, Any]:
        """
        åŠ è½½é…ç½®æ–‡ä»¶
        """
        if config_type == 'json':
            config_file = self.config_dir / f"{config_name}.json"
        else:
            config_file = self.config_dir / f"{config_name}.yaml"
        
        if not config_file.exists():
            raise FileNotFoundError(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        
        if config_type == 'json':
            with open(config_file, 'r') as f:
                return json.load(f)
        else:
            with open(config_file, 'r') as f:
                return yaml.safe_load(f)
    
    def create_custom_config(self, base_config: str, modifications: Dict[str, Any], 
                           save_name: str) -> Dict[str, Any]:
        """
        åŸºäºç°æœ‰é…ç½®åˆ›å»ºè‡ªå®šä¹‰é…ç½®
        """
        base = self.load_config(base_config)
        
        # æ·±åº¦åˆå¹¶é…ç½®
        def deep_merge(base_dict, update_dict):
            for key, value in update_dict.items():
                if key in base_dict and isinstance(base_dict[key], dict) and isinstance(value, dict):
                    deep_merge(base_dict[key], value)
                else:
                    base_dict[key] = value
        
        deep_merge(base, modifications)
        
        # ä¿å­˜æ–°é…ç½®
        save_file = self.config_dir / f"{save_name}.json"
        with open(save_file, 'w') as f:
            json.dump(base, f, indent=2)
        
        print(f"ğŸ’¾ è‡ªå®šä¹‰é…ç½®å·²ä¿å­˜: {save_file}")
        return base


class AdvancedExperimentRunner:
    """
    é«˜çº§å®éªŒè¿è¡Œå™¨
    """
    
    def __init__(self):
        self.config_manager = ConfigurationManager()
        self.experiment_manager = ExperimentManager(base_results_dir="examples/advanced_results")
    
    def adaptive_hyperparameter_tuning(self):
        """
        ç¤ºä¾‹1: è‡ªé€‚åº”è¶…å‚æ•°è°ƒä¼˜
        """
        print("\n" + "=" * 60)
        print("ğŸ¯ ç¤ºä¾‹1: è‡ªé€‚åº”è¶…å‚æ•°è°ƒä¼˜")
        print("=" * 60)
        
        # 1. åŠ è½½æ•°æ®
        data = load_digits()
        X, y = data.data, data.target
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # 2. å®šä¹‰å‚æ•°ç©ºé—´
        param_space = {
            'representation_dim': [32, 64, 128],
            'lr': [0.001, 0.01, 0.1],
            'batch_size': [16, 32, 64],
            'learnable_thresholds': [False, True],
            'uniqueness_constraint': [False, True]
        }
        
        # 3. è‡ªé€‚åº”ç½‘æ ¼æœç´¢
        print("ğŸ” å¼€å§‹è‡ªé€‚åº”å‚æ•°æœç´¢...")
        best_config = None
        best_score = 0
        search_results = []
        
        # ç²—æœç´¢
        print("  ç¬¬ä¸€é˜¶æ®µ: ç²—æœç´¢...")
        coarse_grid = {
            'representation_dim': [32, 128],
            'lr': [0.001, 0.1],
            'learnable_thresholds': [False, True]
        }
        
        for repr_dim in coarse_grid['representation_dim']:
            for lr in coarse_grid['lr']:
                for learnable_thresh in coarse_grid['learnable_thresholds']:
                    config = {
                        'input_dim': X.shape[1],
                        'n_classes': len(np.unique(y)),
                        'representation_dim': repr_dim,
                        'lr': lr,
                        'learnable_thresholds': learnable_thresh,
                        'epochs': 50,
                        'verbose': 0
                    }
                    
                    model = CAACOvRModel(**config)
                    model.fit(X_train_scaled, y_train)
                    score = accuracy_score(y_test, model.predict(X_test_scaled))
                    
                    search_results.append((config.copy(), score))
                    if score > best_score:
                        best_score = score
                        best_config = config.copy()
                    
                    print(f"    repr_dim={repr_dim}, lr={lr}, thresh={learnable_thresh}: {score:.4f}")
        
        # ç»†æœç´¢
        print("  ç¬¬äºŒé˜¶æ®µ: ç»†æœç´¢...")
        fine_search_space = {
            'representation_dim': [max(16, best_config['representation_dim']//2), 
                                 best_config['representation_dim'], 
                                 min(256, best_config['representation_dim']*2)],
            'lr': [best_config['lr']/3, best_config['lr'], best_config['lr']*3],
            'batch_size': [16, 32, 64]
        }
        
        for repr_dim in fine_search_space['representation_dim']:
            for lr in fine_search_space['lr']:
                for batch_size in fine_search_space['batch_size']:
                    config = best_config.copy()
                    config.update({
                        'representation_dim': repr_dim,
                        'lr': lr,
                        'batch_size': batch_size,
                        'epochs': 100
                    })
                    
                    model = CAACOvRModel(**config)
                    model.fit(X_train_scaled, y_train)
                    score = accuracy_score(y_test, model.predict(X_test_scaled))
                    
                    search_results.append((config.copy(), score))
                    if score > best_score:
                        best_score = score
                        best_config = config.copy()
                    
                    print(f"    repr_dim={repr_dim}, lr={lr:.4f}, batch={batch_size}: {score:.4f}")
        
        print(f"\nâœ… æœ€ä½³é…ç½® (å‡†ç¡®ç‡: {best_score:.4f}):")
        for key, value in best_config.items():
            if key not in ['input_dim', 'n_classes', 'verbose']:
                print(f"  {key}: {value}")
        
        # ä¿å­˜æœ€ä½³é…ç½®
        self.config_manager.create_custom_config(
            'model_configs', 
            {'adaptive_best': best_config}, 
            'adaptive_best_config'
        )
        
        return best_config, search_results
    
    def configuration_template_experiment(self):
        """
        ç¤ºä¾‹2: é…ç½®æ¨¡æ¿å®éªŒ
        """
        print("\n" + "=" * 60)
        print("ğŸ“‹ ç¤ºä¾‹2: é…ç½®æ¨¡æ¿å®éªŒ")
        print("=" * 60)
        
        # 1. åˆ›å»ºé»˜è®¤é…ç½®
        self.config_manager.create_default_configs()
        
        # 2. åŠ è½½ä¸åŒé…ç½®æ¨¡æ¿
        configs_to_test = ['small_dataset', 'medium_dataset', 'large_dataset', 'robust_model']
        
        # 3. å‡†å¤‡æµ‹è¯•æ•°æ®
        data = load_wine()
        X, y = data.data, data.target
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # 4. æµ‹è¯•æ¯ä¸ªé…ç½®æ¨¡æ¿
        results = {}
        for config_name in configs_to_test:
            print(f"\nğŸ”§ æµ‹è¯•é…ç½®æ¨¡æ¿: {config_name}")
            
            # åŠ è½½é…ç½®
            model_configs = self.config_manager.load_config('model_configs')
            config = model_configs[config_name].copy()
            config.update({
                'input_dim': X.shape[1],
                'n_classes': len(np.unique(y)),
                'verbose': 0
            })
            
            # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
            model = CAACOvRModel(**config)
            history = model.fit(X_train_scaled, y_train)
            
            # è¯„ä¼°
            predictions = model.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, predictions)
            f1 = f1_score(y_test, predictions, average='macro')
            
            results[config_name] = {
                'accuracy': accuracy,
                'f1_score': f1,
                'training_time': history.get('total_time', 0),
                'final_epoch': history.get('best_epoch', len(history.get('train_losses', [])))
            }
            
            print(f"  âœ… å‡†ç¡®ç‡: {accuracy:.4f}, F1: {f1:.4f}")
            print(f"  â±ï¸ è®­ç»ƒæ—¶é—´: {results[config_name]['training_time']:.2f}s")
        
        # 5. ç»“æœæ¯”è¾ƒ
        print("\nğŸ“Š é…ç½®æ¨¡æ¿å¯¹æ¯”ç»“æœ:")
        print("-" * 80)
        print(f"{'é…ç½®åç§°':<20} {'å‡†ç¡®ç‡':<10} {'F1åˆ†æ•°':<10} {'è®­ç»ƒæ—¶é—´':<12} {'æ”¶æ•›è½®æ¬¡':<10}")
        print("-" * 80)
        for config_name, result in results.items():
            print(f"{config_name:<20} {result['accuracy']:<10.4f} {result['f1_score']:<10.4f} "
                  f"{result['training_time']:<12.2f} {result['final_epoch']:<10}")
        
        return results
    
    def environment_adaptive_config(self):
        """
        ç¤ºä¾‹3: ç¯å¢ƒè‡ªé€‚åº”é…ç½®
        """
        print("\n" + "=" * 60)
        print("ğŸŒ ç¤ºä¾‹3: ç¯å¢ƒè‡ªé€‚åº”é…ç½®")
        print("=" * 60)
        
        # 1. æ£€æµ‹è¿è¡Œç¯å¢ƒ
        import psutil
        import platform
        
        # ç³»ç»Ÿä¿¡æ¯
        cpu_count = psutil.cpu_count()
        memory_gb = psutil.virtual_memory().total / (1024**3)
        
        print(f"ğŸ–¥ï¸ ç³»ç»Ÿä¿¡æ¯:")
        print(f"  CPUæ ¸å¿ƒæ•°: {cpu_count}")
        print(f"  å†…å­˜å®¹é‡: {memory_gb:.1f}GB")
        print(f"  æ“ä½œç³»ç»Ÿ: {platform.system()}")
        
        # 2. æ ¹æ®ç¯å¢ƒè°ƒæ•´é…ç½®
        base_config = {
            'input_dim': 64,  # ç¤ºä¾‹
            'n_classes': 10,  # ç¤ºä¾‹
            'representation_dim': 64,
            'epochs': 100,
            'verbose': 1
        }
        
        # å†…å­˜ä¼˜åŒ–
        if memory_gb < 8:
            print("ğŸ“‰ æ£€æµ‹åˆ°ä½å†…å­˜ç¯å¢ƒï¼Œåº”ç”¨å†…å­˜ä¼˜åŒ–é…ç½®...")
            memory_config = self.config_manager.load_config('performance_configs')['memory_optimized']
            base_config['batch_size'] = 16
            base_config['representation_dim'] = int(base_config['representation_dim'] * 
                                                  memory_config['representation_dim_multiplier'])
            base_config['early_stopping_patience'] = int(20 * 
                                                        memory_config['early_stopping_patience_multiplier'])
        else:
            base_config['batch_size'] = 64
        
        # CPUä¼˜åŒ–
        if cpu_count >= 8:
            print("ğŸš€ æ£€æµ‹åˆ°å¤šæ ¸ç¯å¢ƒï¼Œå¯ç”¨å¹¶è¡Œå¤„ç†...")
            base_config['parallel_processing'] = True
        else:
            base_config['parallel_processing'] = False
        
        # GPUæ£€æµ‹
        try:
            import torch
            if torch.cuda.is_available():
                print("ğŸ® æ£€æµ‹åˆ°GPUï¼Œå¯ç”¨GPUåŠ é€Ÿ...")
                base_config['device'] = 'cuda'
            else:
                base_config['device'] = 'cpu'
        except ImportError:
            print("âš ï¸ æœªå®‰è£…PyTorchï¼Œä½¿ç”¨CPUæ¨¡å¼...")
            base_config['device'] = 'cpu'
        
        print(f"\nâš™ï¸ è‡ªé€‚åº”é…ç½®:")
        for key, value in base_config.items():
            if key not in ['input_dim', 'n_classes']:
                print(f"  {key}: {value}")
        
        # 3. ä¿å­˜ç¯å¢ƒè‡ªé€‚åº”é…ç½®
        env_config = {
            'system_info': {
                'cpu_count': cpu_count,
                'memory_gb': memory_gb,
                'platform': platform.system()
            },
            'adaptive_config': base_config
        }
        
        save_file = self.config_manager.config_dir / "environment_adaptive.json"
        with open(save_file, 'w') as f:
            json.dump(env_config, f, indent=2)
        print(f"ğŸ’¾ ç¯å¢ƒè‡ªé€‚åº”é…ç½®å·²ä¿å­˜: {save_file}")
        
        return env_config
    
    def config_validation_and_testing(self):
        """
        ç¤ºä¾‹4: é…ç½®éªŒè¯å’Œæµ‹è¯•
        """
        print("\n" + "=" * 60)
        print("âœ… ç¤ºä¾‹4: é…ç½®éªŒè¯å’Œæµ‹è¯•")
        print("=" * 60)
        
        # 1. é…ç½®éªŒè¯è§„åˆ™
        validation_rules = {
            'representation_dim': {'min': 8, 'max': 512, 'type': int},
            'lr': {'min': 1e-5, 'max': 1.0, 'type': float},
            'epochs': {'min': 10, 'max': 1000, 'type': int},
            'batch_size': {'min': 4, 'max': 256, 'type': int},
            'early_stopping_patience': {'min': 5, 'max': 100, 'type': int}
        }
        
        def validate_config(config: Dict[str, Any]) -> tuple[bool, List[str]]:
            """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
            errors = []
            
            for param, rules in validation_rules.items():
                if param in config:
                    value = config[param]
                    
                    # ç±»å‹æ£€æŸ¥
                    if not isinstance(value, rules['type']):
                        errors.append(f"{param}: æœŸæœ›ç±»å‹ {rules['type'].__name__}, å¾—åˆ° {type(value).__name__}")
                    
                    # èŒƒå›´æ£€æŸ¥
                    if isinstance(value, (int, float)):
                        if 'min' in rules and value < rules['min']:
                            errors.append(f"{param}: å€¼ {value} å°äºæœ€å°å€¼ {rules['min']}")
                        if 'max' in rules and value > rules['max']:
                            errors.append(f"{param}: å€¼ {value} å¤§äºæœ€å¤§å€¼ {rules['max']}")
            
            return len(errors) == 0, errors
        
        # 2. æµ‹è¯•æœ‰æ•ˆé…ç½®
        valid_config = {
            'input_dim': 20,
            'n_classes': 3,
            'representation_dim': 64,
            'lr': 0.001,
            'epochs': 100,
            'batch_size': 32,
            'early_stopping_patience': 15,
            'verbose': 0
        }
        
        is_valid, errors = validate_config(valid_config)
        print(f"âœ… æœ‰æ•ˆé…ç½®éªŒè¯: {'é€šè¿‡' if is_valid else 'å¤±è´¥'}")
        if errors:
            for error in errors:
                print(f"  âŒ {error}")
        
        # 3. æµ‹è¯•æ— æ•ˆé…ç½®
        invalid_configs = [
            {'representation_dim': 1000, 'lr': 10.0},  # è¶…å‡ºèŒƒå›´
            {'epochs': 'not_a_number'},  # ç±»å‹é”™è¯¯
            {'batch_size': 1000, 'early_stopping_patience': 1}  # å¤šä¸ªé”™è¯¯
        ]
        
        print("\nğŸš« æ— æ•ˆé…ç½®æµ‹è¯•:")
        for i, config in enumerate(invalid_configs, 1):
            test_config = valid_config.copy()
            test_config.update(config)
            
            is_valid, errors = validate_config(test_config)
            print(f"  æµ‹è¯• {i}: {'é€šè¿‡' if is_valid else 'å¤±è´¥'}")
            for error in errors:
                print(f"    âŒ {error}")
        
        # 4. é…ç½®å…¼å®¹æ€§æµ‹è¯•
        print("\nğŸ”— é…ç½®å…¼å®¹æ€§æµ‹è¯•:")
        
        # æµ‹è¯•æå°é…ç½®
        minimal_config = {
            'input_dim': 4,
            'n_classes': 2,
            'representation_dim': 8,
            'epochs': 10,
            'verbose': 0
        }
        
        try:
            model = CAACOvRModel(**minimal_config)
            print("  âœ… æå°é…ç½®: å¯åˆ›å»ºæ¨¡å‹")
        except Exception as e:
            print(f"  âŒ æå°é…ç½®: {e}")
        
        # æµ‹è¯•å¤§å‹é…ç½®
        large_config = {
            'input_dim': 100,
            'n_classes': 10,
            'representation_dim': 256,
            'feature_hidden_dims': [512, 256],
            'abduction_hidden_dims': [256, 128],
            'epochs': 200,
            'verbose': 0
        }
        
        try:
            model = CAACOvRModel(**large_config)
            print("  âœ… å¤§å‹é…ç½®: å¯åˆ›å»ºæ¨¡å‹")
        except Exception as e:
            print(f"  âŒ å¤§å‹é…ç½®: {e}")
        
        return validation_rules
    
    def performance_profiling_experiment(self):
        """
        ç¤ºä¾‹5: æ€§èƒ½åˆ†æå®éªŒ
        """
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ç¤ºä¾‹5: æ€§èƒ½åˆ†æå®éªŒ")
        print("=" * 60)
        
        import time
        import tracemalloc
        
        # 1. å‡†å¤‡æµ‹è¯•æ•°æ®
        data = load_digits()
        X, y = data.data, data.target
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.3, random_state=42, stratify=y
        )
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # 2. æµ‹è¯•ä¸åŒé…ç½®çš„æ€§èƒ½
        test_configs = {
            'lightweight': {
                'representation_dim': 32,
                'feature_hidden_dims': [32],
                'abduction_hidden_dims': [32, 16],
                'epochs': 50
            },
            'standard': {
                'representation_dim': 64,
                'feature_hidden_dims': [128, 64],
                'abduction_hidden_dims': [64, 32],
                'epochs': 100
            },
            'heavy': {
                'representation_dim': 128,
                'feature_hidden_dims': [256, 128],
                'abduction_hidden_dims': [128, 64],
                'epochs': 150
            }
        }
        
        performance_results = {}
        
        for config_name, config in test_configs.items():
            print(f"\nğŸ”§ æµ‹è¯•é…ç½®: {config_name}")
            
            # åŸºç¡€é…ç½®
            full_config = {
                'input_dim': X.shape[1],
                'n_classes': len(np.unique(y)),
                'verbose': 0,
                **config
            }
            
            # å¼€å§‹å†…å­˜è¿½è¸ª
            tracemalloc.start()
            
            # åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
            start_time = time.time()
            model = CAACOvRModel(**full_config)
            
            # è®­ç»ƒæ—¶é—´
            train_start = time.time()
            history = model.fit(X_train_scaled, y_train)
            train_time = time.time() - train_start
            
            # é¢„æµ‹æ—¶é—´
            predict_start = time.time()
            predictions = model.predict(X_test_scaled)
            predict_time = time.time() - predict_start
            
            total_time = time.time() - start_time
            
            # å†…å­˜ä½¿ç”¨
            current, peak = tracemalloc.get_traced_memory()
            tracemalloc.stop()
            
            # å‡†ç¡®ç‡
            accuracy = accuracy_score(y_test, predictions)
            
            performance_results[config_name] = {
                'accuracy': accuracy,
                'train_time': train_time,
                'predict_time': predict_time,
                'total_time': total_time,
                'memory_current_mb': current / (1024 * 1024),
                'memory_peak_mb': peak / (1024 * 1024),
                'parameters': sum(p.numel() for p in model.model.parameters()),
                'epochs_used': history.get('best_epoch', len(history.get('train_losses', [])))
            }
            
            print(f"  âœ… å‡†ç¡®ç‡: {accuracy:.4f}")
            print(f"  â±ï¸ è®­ç»ƒæ—¶é—´: {train_time:.2f}s")
            print(f"  ğŸ¯ é¢„æµ‹æ—¶é—´: {predict_time:.4f}s")
            print(f"  ğŸ’¾ å³°å€¼å†…å­˜: {peak / (1024 * 1024):.1f}MB")
        
        # 3. æ€§èƒ½æŠ¥å‘Š
        print("\n" + "=" * 80)
        print("ğŸ“Š æ€§èƒ½åˆ†ææŠ¥å‘Š")
        print("=" * 80)
        print(f"{'é…ç½®':<12} {'å‡†ç¡®ç‡':<8} {'è®­ç»ƒæ—¶é—´':<10} {'é¢„æµ‹æ—¶é—´':<10} {'å³°å€¼å†…å­˜':<10} {'å‚æ•°æ•°é‡':<10}")
        print("-" * 80)
        
        for config_name, result in performance_results.items():
            print(f"{config_name:<12} {result['accuracy']:<8.4f} {result['train_time']:<10.2f} "
                  f"{result['predict_time']:<10.4f} {result['memory_peak_mb']:<10.1f} {result['parameters']:<10}")
        
        # 4. æ•ˆç‡åˆ†æ
        print("\nğŸ“ˆ æ•ˆç‡åˆ†æ:")
        for config_name, result in performance_results.items():
            efficiency = result['accuracy'] / result['train_time']
            memory_efficiency = result['accuracy'] / result['memory_peak_mb']
            print(f"  {config_name}: æ—¶é—´æ•ˆç‡={efficiency:.6f}, å†…å­˜æ•ˆç‡={memory_efficiency:.6f}")
        
        # 5. ä¿å­˜æ€§èƒ½æŠ¥å‘Š
        report_file = Path("examples/advanced_results/performance_report.json")
        report_file.parent.mkdir(exist_ok=True)
        
        with open(report_file, 'w') as f:
            json.dump({
                'timestamp': datetime.now().isoformat(),
                'system_info': {
                    'python_version': platform.python_version(),
                    'platform': platform.platform()
                },
                'performance_results': performance_results
            }, f, indent=2)
        
        print(f"ğŸ’¾ æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        return performance_results


def main():
    """
    è¿è¡Œæ‰€æœ‰é«˜çº§é…ç½®ç¤ºä¾‹
    """
    print("âš™ï¸ CAACé¡¹ç›®é«˜çº§é…ç½®ç¤ºä¾‹")
    print("=" * 60)
    print("æœ¬ç¤ºä¾‹å±•ç¤ºé«˜çº§é…ç½®ç®¡ç†å’Œæ€§èƒ½ä¼˜åŒ–æŠ€å·§")
    print()
    
    runner = AdvancedExperimentRunner()
    
    try:
        # 1. è‡ªé€‚åº”è¶…å‚æ•°è°ƒä¼˜
        best_config, search_results = runner.adaptive_hyperparameter_tuning()
        
        # 2. é…ç½®æ¨¡æ¿å®éªŒ
        template_results = runner.configuration_template_experiment()
        
        # 3. ç¯å¢ƒè‡ªé€‚åº”é…ç½®
        env_config = runner.environment_adaptive_config()
        
        # 4. é…ç½®éªŒè¯å’Œæµ‹è¯•
        validation_rules = runner.config_validation_and_testing()
        
        # 5. æ€§èƒ½åˆ†æå®éªŒ
        performance_results = runner.performance_profiling_experiment()
        
        # æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸŠ æ‰€æœ‰é«˜çº§é…ç½®ç¤ºä¾‹å®Œæˆ!")
        print("=" * 60)
        print("ğŸ“Š ä¸»è¦æˆæœ:")
        print(f"  - æœ€ä½³è¶…å‚æ•°å‡†ç¡®ç‡: {max(r[1] for r in search_results):.4f}")
        print(f"  - é…ç½®æ¨¡æ¿æµ‹è¯•: {len(template_results)} ä¸ªæ¨¡æ¿")
        print(f"  - ç¯å¢ƒè‡ªé€‚åº”: å·²ä¿å­˜ç¯å¢ƒç‰¹å®šé…ç½®")
        print(f"  - æ€§èƒ½åˆ†æ: {len(performance_results)} ä¸ªé…ç½®å¯¹æ¯”")
        print()
        print("ğŸ’¡ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("  - examples/configs/*.json|*.yaml - é…ç½®æ¨¡æ¿")
        print("  - examples/advanced_results/ - å®éªŒç»“æœ")
        print()
        print("ğŸ¯ æœ€ä½³å®è·µæ€»ç»“:")
        print("  1. æ ¹æ®æ•°æ®é›†å¤§å°é€‰æ‹©åˆé€‚çš„é…ç½®æ¨¡æ¿")
        print("  2. ä½¿ç”¨è‡ªé€‚åº”è¶…å‚æ•°æœç´¢ä¼˜åŒ–æ€§èƒ½")
        print("  3. è€ƒè™‘è¿è¡Œç¯å¢ƒè°ƒæ•´é…ç½®å‚æ•°")
        print("  4. å®šæœŸéªŒè¯å’Œæµ‹è¯•é…ç½®å…¼å®¹æ€§")
        print("  5. ç›‘æ§æ€§èƒ½æŒ‡æ ‡ä¼˜åŒ–èµ„æºä½¿ç”¨")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œé«˜çº§é…ç½®ç¤ºä¾‹æ—¶å‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ç¯å¢ƒé…ç½®å’Œä¾èµ–å®‰è£…")


if __name__ == "__main__":
    main() 