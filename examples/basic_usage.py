"""
ğŸš€ CAACé¡¹ç›®åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

æœ¬æ–‡ä»¶å±•ç¤ºCAACé¡¹ç›®çš„åŸºæœ¬ä½¿ç”¨æ–¹æ³•ï¼ŒåŒ…æ‹¬ï¼š
- æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹
- å®éªŒè¿è¡Œ
- ç»“æœå¯è§†åŒ–

è¯·åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼špython examples/basic_usage.py
"""

import sys
import os
import numpy as np
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

from src.models.caac_ovr_model import CAACOvRModel
from src.experiments.experiment_manager import ExperimentManager
from sklearn.datasets import load_iris, load_wine
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt


def example_1_direct_model_usage():
    """
    ç¤ºä¾‹1: ç›´æ¥ä½¿ç”¨CAACæ¨¡å‹
    """
    print("=" * 60)
    print("ğŸ¯ ç¤ºä¾‹1: ç›´æ¥ä½¿ç”¨CAACæ¨¡å‹")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½Irisæ•°æ®é›†...")
    data = load_iris()
    X, y = data.data, data.target
    
    # 2. æ•°æ®é¢„å¤„ç†
    print("ğŸ”§ æ•°æ®é¢„å¤„ç†...")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 3. åˆ›å»ºå’Œè®­ç»ƒæ¨¡å‹
    print("ğŸ§  åˆ›å»ºCAACæ¨¡å‹...")
    model = CAACOvRModel(
        input_dim=X_train_scaled.shape[1],
        representation_dim=32,
        latent_dim=16,
        n_classes=len(np.unique(y_train)),
        feature_hidden_dims=[32],
        abduction_hidden_dims=[32, 16],
        lr=0.01,
        batch_size=16,
        epochs=50,
        early_stopping_patience=10
    )
    
    print("ğŸ”¥ å¼€å§‹è®­ç»ƒ...")
    history = model.fit(X_train_scaled, y_train, verbose=1)
    
    # 4. æ¨¡å‹é¢„æµ‹
    print("ğŸ¯ è¿›è¡Œé¢„æµ‹...")
    predictions = model.predict(X_test_scaled)
    probabilities = model.predict_proba(X_test_scaled)
    
    # 5. è¯„ä¼°ç»“æœ
    accuracy = accuracy_score(y_test, predictions)
    print(f"âœ… æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.4f}")
    print("\nğŸ“Š è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print(classification_report(y_test, predictions, target_names=data.target_names))
    
    # 6. ç®€å•å¯è§†åŒ–
    if hasattr(plt, 'figure'):
        plt.figure(figsize=(10, 4))
        
        plt.subplot(1, 2, 1)
        plt.plot(history['train_losses'], label='Training Loss')
        plt.title('Training Loss Over Time')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        
        plt.subplot(1, 2, 2)
        plt.plot(history['train_accuracies'], label='Training Accuracy')
        plt.title('Training Accuracy Over Time')
        plt.xlabel('Epoch')
        plt.ylabel('Accuracy')
        plt.legend()
        
        plt.tight_layout()
        plt.savefig('basic_usage_training_history.png', dpi=300, bbox_inches='tight')
        print("ğŸ“ˆ è®­ç»ƒå†å²å·²ä¿å­˜ä¸º 'basic_usage_training_history.png'")
        plt.close()
    
    return model, accuracy


def example_2_experiment_manager():
    """
    ç¤ºä¾‹2: ä½¿ç”¨å®éªŒç®¡ç†å™¨
    """
    print("\n" + "=" * 60)
    print("ğŸ”¬ ç¤ºä¾‹2: ä½¿ç”¨å®éªŒç®¡ç†å™¨")
    print("=" * 60)
    
    # 1. åˆ›å»ºå®éªŒç®¡ç†å™¨
    print("ğŸ“‹ åˆ›å»ºå®éªŒç®¡ç†å™¨...")
    manager = ExperimentManager(base_results_dir="examples/results")
    
    # 2. æŸ¥çœ‹å¯ç”¨å®éªŒ
    print("ğŸ“ å¯ç”¨å®éªŒç±»å‹:")
    available_experiments = manager.list_available_experiments()
    for exp in available_experiments:
        print(f"  - {exp}")
    
    # 3. è¿è¡Œå¿«é€Ÿå®éªŒ
    print("\nğŸš€ è¿è¡Œå¿«é€Ÿé²æ£’æ€§æµ‹è¯•...")
    try:
        result_dir = manager.run_quick_robustness_test(
            datasets=['iris', 'wine'],  # é™åˆ¶æ•°æ®é›†ä»¥åŠ å¿«é€Ÿåº¦
            epochs=30,  # å‡å°‘è®­ç»ƒè½®æ•°
            noise_levels=[0.0, 0.1, 0.2]  # å‡å°‘å™ªå£°æ°´å¹³
        )
        print(f"âœ… å®éªŒå®Œæˆ! ç»“æœä¿å­˜åœ¨: {result_dir}")
        
        # 4. åˆ›å»ºå®éªŒæ€»ç»“
        summary = manager.create_experiment_summary(result_dir)
        print("\nğŸ“Š å®éªŒæ€»ç»“:")
        print(f"  - ç”Ÿæˆæ–‡ä»¶æ•°: {len(summary.get('files', []))}")
        print(f"  - å®éªŒæ—¶é—´: {summary.get('timestamp', 'N/A')}")
        
        # 5. æ˜¾ç¤ºç”Ÿæˆçš„æ–‡ä»¶
        if summary.get('files'):
            print("  - ç”Ÿæˆçš„æ–‡ä»¶:")
            for file in summary['files'][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
                print(f"    â€¢ {file}")
            if len(summary['files']) > 5:
                print(f"    â€¢ ... è¿˜æœ‰ {len(summary['files']) - 5} ä¸ªæ–‡ä»¶")
        
    except Exception as e:
        print(f"âŒ å®éªŒè¿è¡Œå¤±è´¥: {e}")
        print("è¯·æ£€æŸ¥å®éªŒæ¨¡å—æ˜¯å¦æ­£ç¡®é…ç½®")
    
    return manager


def example_3_custom_configuration():
    """
    ç¤ºä¾‹3: è‡ªå®šä¹‰é…ç½®
    """
    print("\n" + "=" * 60)
    print("âš™ï¸ ç¤ºä¾‹3: è‡ªå®šä¹‰é…ç½®")
    print("=" * 60)
    
    # 1. åŠ è½½ä¸åŒæ•°æ®é›†
    print("ğŸ“Š åŠ è½½Wineæ•°æ®é›†...")
    data = load_wine()
    X, y = data.data, data.target
    
    # 2. åˆ›å»ºé«˜çº§é…ç½®çš„æ¨¡å‹
    print("ğŸ§  åˆ›å»ºé«˜çº§é…ç½®æ¨¡å‹...")
    advanced_model = CAACOvRModel(
        input_dim=X.shape[1],
        representation_dim=64,
        latent_dim=32,
        n_classes=len(np.unique(y)),
        feature_hidden_dims=[128, 64],
        abduction_hidden_dims=[64, 32],
        lr=0.001,
        batch_size=32,
        epochs=100,
        learnable_thresholds=True,  # å¯ç”¨å¯å­¦ä¹ é˜ˆå€¼
        uniqueness_constraint=True,  # å¯ç”¨å”¯ä¸€æ€§çº¦æŸ
        uniqueness_weight=0.1,
        early_stopping_patience=15
    )
    
    # 3. æ•°æ®é¢„å¤„ç†å’Œåˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 4. è®­ç»ƒæ¨¡å‹
    print("ğŸ”¥ è®­ç»ƒé«˜çº§é…ç½®æ¨¡å‹...")
    history = advanced_model.fit(X_train_scaled, y_train, verbose=1)
    
    # 5. è¯„ä¼°æ€§èƒ½
    predictions = advanced_model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, predictions)
    
    print(f"âœ… é«˜çº§æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.4f}")
    
    # 6. å‚æ•°æ¢ç´¢
    print("\nğŸ”§ æ¨¡å‹å‚æ•°:")
    params = advanced_model.get_params()
    key_params = ['representation_dim', 'latent_dim', 'lr', 'learnable_thresholds', 'uniqueness_constraint']
    for param in key_params:
        if param in params:
            print(f"  - {param}: {params[param]}")
    
    return advanced_model, accuracy


def example_4_comparison_multiple_models():
    """
    ç¤ºä¾‹4: å¤šæ¨¡å‹å¯¹æ¯”
    """
    print("\n" + "=" * 60)
    print("ğŸ“Š ç¤ºä¾‹4: å¤šæ¨¡å‹å¯¹æ¯”")
    print("=" * 60)
    
    # 1. å‡†å¤‡æ•°æ®
    data = load_iris()
    X, y = data.data, data.target
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # 2. å®šä¹‰ä¸åŒé…ç½®çš„æ¨¡å‹
    models = {
        'CAAC Basic': CAACOvRModel(
            input_dim=X.shape[1], n_classes=len(np.unique(y)),
            representation_dim=32, epochs=30
        ),
        'CAAC + Learnable Thresholds': CAACOvRModel(
            input_dim=X.shape[1], n_classes=len(np.unique(y)),
            representation_dim=32, epochs=30, learnable_thresholds=True
        ),
        'CAAC + Uniqueness': CAACOvRModel(
            input_dim=X.shape[1], n_classes=len(np.unique(y)),
            representation_dim=32, epochs=30, uniqueness_constraint=True
        )
    }
    
    # 3. è®­ç»ƒå’Œè¯„ä¼°æ‰€æœ‰æ¨¡å‹
    results = {}
    for name, model in models.items():
        print(f"\nğŸ”¥ è®­ç»ƒ {name}...")
        history = model.fit(X_train_scaled, y_train, verbose=0)
        predictions = model.predict(X_test_scaled)
        accuracy = accuracy_score(y_test, predictions)
        results[name] = accuracy
        print(f"âœ… {name} å‡†ç¡®ç‡: {accuracy:.4f}")
    
    # 4. æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
    print("\n" + "=" * 40)
    print("ğŸ“Š æ¨¡å‹å¯¹æ¯”ç»“æœ")
    print("=" * 40)
    sorted_results = sorted(results.items(), key=lambda x: x[1], reverse=True)
    for rank, (name, accuracy) in enumerate(sorted_results, 1):
        print(f"{rank}. {name:<25}: {accuracy:.4f}")
    
    return results


def main():
    """
    è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    """
    print("ğŸš€ CAACé¡¹ç›®åŸºç¡€ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    print("æœ¬ç¤ºä¾‹å°†æ¼”ç¤ºCAACé¡¹ç›®çš„åŸºæœ¬ä½¿ç”¨æ–¹æ³•")
    print()
    
    try:
        # ç¤ºä¾‹1: ç›´æ¥æ¨¡å‹ä½¿ç”¨
        model1, acc1 = example_1_direct_model_usage()
        
        # ç¤ºä¾‹2: å®éªŒç®¡ç†å™¨
        manager = example_2_experiment_manager()
        
        # ç¤ºä¾‹3: è‡ªå®šä¹‰é…ç½®
        model3, acc3 = example_3_custom_configuration()
        
        # ç¤ºä¾‹4: å¤šæ¨¡å‹å¯¹æ¯”
        comparison_results = example_4_comparison_multiple_models()
        
        # æ€»ç»“
        print("\n" + "=" * 60)
        print("ğŸŠ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        print("=" * 60)
        print(f"ğŸ“Š ç›´æ¥æ¨¡å‹ä½¿ç”¨å‡†ç¡®ç‡: {acc1:.4f}")
        print(f"âš™ï¸ é«˜çº§é…ç½®æ¨¡å‹å‡†ç¡®ç‡: {acc3:.4f}")
        print(f"ğŸ† æœ€ä½³å¯¹æ¯”æ¨¡å‹: {max(comparison_results.items(), key=lambda x: x[1])[0]}")
        print()
        print("ğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("  1. æŸ¥çœ‹ docs/api/ è·å–è¯¦ç»†APIæ–‡æ¡£")
        print("  2. è¿è¡Œ python run_experiments.py --quick è¿›è¡Œå¿«é€Ÿå®éªŒ")
        print("  3. å‚è€ƒ examples/custom_experiment.py å­¦ä¹ è‡ªå®šä¹‰å®éªŒ")
        
    except Exception as e:
        print(f"âŒ è¿è¡Œç¤ºä¾‹æ—¶å‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ç¯å¢ƒé…ç½®å’Œä¾èµ–å®‰è£…")


if __name__ == "__main__":
    # ç¡®ä¿ç»“æœç›®å½•å­˜åœ¨
    os.makedirs("examples/results", exist_ok=True)
    
    # è¿è¡Œç¤ºä¾‹
    main() 