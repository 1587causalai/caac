"""
æ ‡ç­¾å™ªå£°æ³¨å…¥æ¼”ç¤ºè„šæœ¬

æ¼”ç¤ºDataProcessorç±»ä¸­æ–°å¢çš„æ ‡ç­¾å™ªå£°æ³¨å…¥åŠŸèƒ½ï¼ŒåŒ…æ‹¬å„ç§å™ªå£°ç±»å‹çš„æ•ˆæœå¯¹æ¯”ã€‚
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.datasets import load_iris, load_wine
import sys
import os

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'src'))

from data.data_processor import DataProcessor

def demo_label_noise_injection():
    """æ¼”ç¤ºæ ‡ç­¾å™ªå£°æ³¨å…¥åŠŸèƒ½"""
    
    print("ğŸ”¬ Label Noise Injection Demo")
    print("=" * 50)
    
    # åŠ è½½æ•°æ®é›†
    print("ğŸ“ Loading datasets...")
    datasets = {
        'Iris': load_iris(),
        'Wine': load_wine()
    }
    
    # å™ªå£°ç±»å‹åˆ—è¡¨
    noise_types = [
        'random_uniform',
        'proportional', 
        'majority_bias',
        'minority_bias',
        'adjacent',
        'flip_pairs'
    ]
    
    # å™ªå£°æ°´å¹³
    noise_levels = [0.1, 0.2, 0.3]
    
    # ä¸ºæ¯ä¸ªæ•°æ®é›†æµ‹è¯•å™ªå£°æ³¨å…¥
    for dataset_name, dataset in datasets.items():
        print(f"\nğŸ“Š Testing dataset: {dataset_name}")
        print("-" * 30)
        
        X, y = dataset.data, dataset.target
        target_names = dataset.target_names
        
        print(f"Dataset info: {len(X)} samples, {len(np.unique(y))} classes")
        
        # æ˜¾ç¤ºåŸå§‹ç±»åˆ«åˆ†å¸ƒ
        original_dist = {f'Class {i} ({target_names[i]})': np.sum(y == i) 
                        for i in range(len(target_names))}
        print("Original distribution:", original_dist)
        
        # æµ‹è¯•ä¸åŒå™ªå£°ç±»å‹
        for noise_type in noise_types:
            print(f"\nğŸ§ª Testing noise type: {noise_type}")
            
            for noise_level in noise_levels:
                try:
                    # æ³¨å…¥å™ªå£°
                    y_noisy, noise_info = DataProcessor.inject_label_noise(
                        y, noise_level, noise_type, random_state=42
                    )
                    
                    # æ˜¾ç¤ºç»“æœ
                    print(f"  ğŸ“ˆ Noise level {noise_level:.1%}: "
                          f"{noise_info['changes']} samples changed")
                    
                    # æ˜¾ç¤ºæ ‡ç­¾å˜åŒ–ç»Ÿè®¡
                    if noise_info['label_changes']:
                        for orig_label, changes in noise_info['label_changes'].items():
                            for new_label, count in changes.items():
                                orig_name = target_names[orig_label]
                                new_name = target_names[new_label]
                                print(f"    {orig_name} -> {new_name}: {count} changes")
                
                except Exception as e:
                    print(f"  âŒ Error with {noise_type} at {noise_level:.1%}: {str(e)}")
    
    print("\nâœ… Demo completed!")
    
def visualize_noise_effects():
    """å¯è§†åŒ–å™ªå£°æ•ˆæœ"""
    print("\nğŸ¨ Creating visualizations...")
    
    # åŠ è½½irisæ•°æ®é›†
    iris = load_iris()
    X, y = iris.data, iris.target
    
    # æµ‹è¯•å‚æ•°
    noise_level = 0.2
    noise_types = ['random_uniform', 'proportional', 'majority_bias', 'minority_bias']
    
    # åˆ›å»ºå­å›¾
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    axes = axes.ravel()
    
    # ç»˜åˆ¶åŸå§‹åˆ†å¸ƒ
    ax = axes[0]
    unique_labels, counts = np.unique(y, return_counts=True)
    bars = ax.bar(range(len(unique_labels)), counts, 
                  color=['red', 'green', 'blue'], alpha=0.7)
    ax.set_title('Original Distribution', fontsize=12, fontweight='bold')
    ax.set_xlabel('Class')
    ax.set_ylabel('Count')
    ax.set_xticks(range(len(unique_labels)))
    ax.set_xticklabels([f'Class {i}' for i in unique_labels])
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, count in zip(bars, counts):
        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                str(count), ha='center', va='bottom')
    
    # ä¸ºæ¯ç§å™ªå£°ç±»å‹ç»˜åˆ¶åˆ†å¸ƒ
    for idx, noise_type in enumerate(noise_types, 1):
        ax = axes[idx]
        
        # æ³¨å…¥å™ªå£°
        y_noisy, noise_info = DataProcessor.inject_label_noise(
            y, noise_level, noise_type, random_state=42
        )
        
        # ç»˜åˆ¶æ–°åˆ†å¸ƒ
        unique_labels_new, counts_new = np.unique(y_noisy, return_counts=True)
        bars = ax.bar(range(len(unique_labels_new)), counts_new, 
                      color=['red', 'green', 'blue'], alpha=0.7)
        
        ax.set_title(f'{noise_type.replace("_", " ").title()}\n'
                    f'({noise_info["changes"]} changes)', 
                    fontsize=11, fontweight='bold')
        ax.set_xlabel('Class')
        ax.set_ylabel('Count')
        ax.set_xticks(range(len(unique_labels_new)))
        ax.set_xticklabels([f'Class {i}' for i in unique_labels_new])
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, count in zip(bars, counts_new):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, 
                    str(count), ha='center', va='bottom')
    
    # éšè—å¤šä½™çš„å­å›¾
    axes[5].set_visible(False)
    
    plt.tight_layout()
    plt.suptitle(f'Label Noise Effects Comparison (Noise Level: {noise_level:.1%})', 
                 fontsize=14, fontweight='bold', y=1.02)
    
    # ä¿å­˜å›¾ç‰‡
    plt.savefig('label_noise_effects.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š Visualization saved as 'label_noise_effects.png'")
    plt.show()

def compare_noise_robustness():
    """æ¯”è¾ƒä¸åŒå™ªå£°ç±»å‹å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“"""
    print("\nğŸ§ª Comparing noise robustness...")
    
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score
    from sklearn.preprocessing import StandardScaler
    
    # åŠ è½½æ•°æ®
    iris = load_iris()
    X, y = iris.data, iris.target
    
    # åˆ†å‰²æ•°æ®
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )
    
    # æ ‡å‡†åŒ–ç‰¹å¾
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # æµ‹è¯•å‚æ•°
    noise_levels = [0.0, 0.1, 0.2, 0.3, 0.4]
    noise_types = ['random_uniform', 'proportional', 'majority_bias', 'minority_bias']
    
    # å­˜å‚¨ç»“æœ
    results = []
    
    for noise_type in noise_types:
        for noise_level in noise_levels:
            # æ³¨å…¥å™ªå£°
            y_train_noisy, _ = DataProcessor.inject_label_noise(
                y_train, noise_level, noise_type, random_state=42
            )
            
            # è®­ç»ƒæ¨¡å‹
            model = LogisticRegression(random_state=42, max_iter=1000)
            model.fit(X_train_scaled, y_train_noisy)
            
            # è¯„ä¼°ï¼ˆåœ¨å¹²å‡€çš„æµ‹è¯•é›†ä¸Šï¼‰
            y_pred = model.predict(X_test_scaled)
            accuracy = accuracy_score(y_test, y_pred)
            
            results.append({
                'noise_type': noise_type,
                'noise_level': noise_level,
                'accuracy': accuracy
            })
    
    # åˆ›å»ºç»“æœDataFrame
    results_df = pd.DataFrame(results)
    
    # å¯è§†åŒ–ç»“æœ
    plt.figure(figsize=(12, 8))
    
    for noise_type in noise_types:
        data = results_df[results_df['noise_type'] == noise_type]
        plt.plot(data['noise_level'], data['accuracy'], 
                marker='o', linewidth=2, markersize=8,
                label=noise_type.replace('_', ' ').title())
    
    plt.xlabel('Noise Level', fontsize=12)
    plt.ylabel('Test Accuracy', fontsize=12)
    plt.title('Model Robustness to Different Label Noise Types', 
              fontsize=14, fontweight='bold')
    plt.legend(fontsize=10)
    plt.grid(True, alpha=0.3)
    plt.ylim(0, 1.05)
    
    # ä¿å­˜å›¾ç‰‡
    plt.savefig('noise_robustness_comparison.png', dpi=300, bbox_inches='tight')
    print("ğŸ“Š Robustness comparison saved as 'noise_robustness_comparison.png'")
    plt.show()
    
    return results_df

if __name__ == "__main__":
    # è¿è¡Œæ¼”ç¤º
    demo_label_noise_injection()
    
    # åˆ›å»ºå¯è§†åŒ–
    visualize_noise_effects()
    
    # æ¯”è¾ƒé²æ£’æ€§
    results_df = compare_noise_robustness()
    
    print("\nğŸ“‹ Final Results Summary:")
    print(results_df.groupby(['noise_type'])['accuracy'].agg(['mean', 'std']).round(3)) 