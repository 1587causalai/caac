#!/usr/bin/env python3
"""
CAACé²æ£’æ€§å¿«é€Ÿæµ‹è¯• - å‚æ•°åŒ–5åˆ†é’ŸéªŒè¯ç‰ˆæœ¬
æ”¯æŒè‡ªå®šä¹‰å™ªå£°æ°´å¹³å’Œç½‘ç»œç»“æ„å‚æ•°ï¼Œåªä½¿ç”¨å°è§„æ¨¡æ•°æ®é›†è¿›è¡Œå¿«é€ŸéªŒè¯
"""

import sys
import argparse
sys.path.append('src')

def run_quick_robustness_test(
    noise_levels=None,
    representation_dim=128,
    feature_hidden_dims=None,
    abduction_hidden_dims=None,
    batch_size=64,
    epochs=100,  # å¿«é€Ÿæµ‹è¯•ä½¿ç”¨è¾ƒå°‘çš„epochs
    learning_rate=0.001,
    early_stopping_patience=10,
    datasets=None
):
    """
    è¿è¡Œå‚æ•°åŒ–çš„å¿«é€Ÿé²æ£’æ€§æµ‹è¯•
    
    Args:
        noise_levels: List[float] - å™ªå£°æ°´å¹³åˆ—è¡¨ï¼Œå¦‚ [0.0, 0.10, 0.20]
        representation_dim: int - è¡¨å¾ç»´åº¦ï¼Œé»˜è®¤128
        feature_hidden_dims: List[int] - ç‰¹å¾ç½‘ç»œéšè—å±‚ç»´åº¦ï¼Œé»˜è®¤[64]
        abduction_hidden_dims: List[int] - æ¨æ–­ç½‘ç»œéšè—å±‚ç»´åº¦ï¼Œé»˜è®¤[128, 64]
        batch_size: int - æ‰¹é‡å¤§å°ï¼Œé»˜è®¤64
        epochs: int - è®­ç»ƒè½®æ•°ï¼Œé»˜è®¤100ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
        learning_rate: float - å­¦ä¹ ç‡ï¼Œé»˜è®¤0.001
        early_stopping_patience: int - æ—©åœè€å¿ƒå€¼ï¼Œé»˜è®¤10ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
        datasets: List[str] - æ•°æ®é›†åˆ—è¡¨ï¼Œé»˜è®¤ä½¿ç”¨å°è§„æ¨¡æ•°æ®é›†
    """
    # è®¾ç½®é»˜è®¤å‚æ•°ï¼ˆå¿«é€Ÿæµ‹è¯•é…ç½®ï¼‰
    if noise_levels is None:
        noise_levels = [0.0, 0.10, 0.20]  # å¿«é€Ÿæµ‹è¯•åªç”¨3ä¸ªå™ªå£°æ°´å¹³
    if feature_hidden_dims is None:
        feature_hidden_dims = [64]
    if abduction_hidden_dims is None:
        abduction_hidden_dims = [128, 64]
    if datasets is None:
        datasets = ['iris', 'wine', 'breast_cancer', 'optical_digits']  # åªç”¨å°æ•°æ®é›†
    
    print("ğŸš€ CAACæ–¹æ³•Outlieré²æ£’æ€§å‚æ•°åŒ–å¿«é€Ÿæµ‹è¯•")
    print("=" * 60)
    print("ğŸ“Š æµ‹è¯•é…ç½®:")
    print(f"  â€¢ æ•°æ®é›†: ä»…å°è§„æ¨¡æ•°æ®é›† ({len(datasets)}ä¸ª)")
    print("  â€¢ æ–¹æ³•: CAAC(Cauchy), CAAC(Gaussian), MLP(Softmax), MLP(OvR), MLP(Hinge)")
    print(f"  â€¢ å™ªå£°æ°´å¹³: {[f'{x:.1%}' for x in noise_levels]}")
    print("  â€¢ æ•°æ®åˆ†å‰²: 70% train / 15% val / 15% test")
    print("ğŸ“ˆ ç½‘ç»œç»“æ„:")
    print(f"  â€¢ è¡¨å¾ç»´åº¦: {representation_dim}")
    print(f"  â€¢ ç‰¹å¾ç½‘ç»œéšè—å±‚: {feature_hidden_dims}")
    print(f"  â€¢ æ¨æ–­ç½‘ç»œéšè—å±‚: {abduction_hidden_dims}")
    print("âš™ï¸ è®­ç»ƒå‚æ•° (å¿«é€Ÿé…ç½®):")
    print(f"  â€¢ æ‰¹é‡å¤§å°: {batch_size}")
    print(f"  â€¢ è®­ç»ƒè½®æ•°: {epochs}")
    print(f"  â€¢ å­¦ä¹ ç‡: {learning_rate}")
    print(f"  â€¢ æ—©åœè€å¿ƒå€¼: {early_stopping_patience}")
    print(f"  â€¢ é¢„è®¡æ—¶é—´: 3-5åˆ†é’Ÿ")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®é›†å¹¶æ˜¾ç¤ºé€‰æ‹©
    from run_standard_robustness_test import run_parameterized_outlier_robustness_experiments
    from compare_methods_outlier_robustness import load_datasets
    from compare_methods_outlier_robustness import create_robustness_visualizations, create_robustness_heatmap
    from compare_methods_outlier_robustness import analyze_robustness_results, generate_robustness_report
    
    print("\nğŸ“Š åŠ è½½æ•°æ®é›†...")
    all_datasets = load_datasets()
    
    # è¿‡æ»¤é€‰æ‹©çš„æ•°æ®é›†
    filtered_datasets = {k: v for k, v in all_datasets.items() if k in datasets}
    
    print(f"\nğŸ¯ å¿«é€Ÿæµ‹è¯•å°†ä½¿ç”¨ä»¥ä¸‹{len(filtered_datasets)}ä¸ªæ•°æ®é›†:")
    total_samples = 0
    for key, dataset in filtered_datasets.items():
        n_samples, n_features = dataset['data'].shape
        n_classes = len(set(dataset['target']))
        size_label = dataset.get('size', 'unknown')
        total_samples += n_samples
        print(f"  â€¢ {dataset['name']}: {n_samples:,}æ ·æœ¬, {n_features}ç‰¹å¾, {n_classes}ç±» [{size_label}]")
    
    print(f"\nğŸ“ˆ æ€»è®¡: {total_samples:,}æ ·æœ¬ across {len(filtered_datasets)}ä¸ªæ•°æ®é›†")
    
    # ç¡®è®¤å¼€å§‹
    print(f"\nâš ï¸  æ³¨æ„: è¿™å°†è¿è¡Œ {len(filtered_datasets)} Ã— {len(noise_levels)}å™ªå£°æ°´å¹³ Ã— 5æ–¹æ³• = {len(filtered_datasets)*len(noise_levels)*5} ä¸ªå®éªŒ")
    
    import time
    print("\nâ° å®éªŒå°†åœ¨3ç§’åè‡ªåŠ¨å¼€å§‹...")
    for i in range(3, 0, -1):
        print(f"   {i}...")
        time.sleep(1)
    
    print("\nğŸš€ å¼€å§‹å¿«é€Ÿæµ‹è¯•!")
    print("=" * 60)
    
    try:
        # è¿è¡Œå®éªŒï¼Œä½¿ç”¨å¿«é€Ÿé…ç½®
        results_df = run_parameterized_outlier_robustness_experiments(
            filtered_datasets,
            noise_levels=noise_levels,
            representation_dim=representation_dim,
            feature_hidden_dims=feature_hidden_dims,
            abduction_hidden_dims=abduction_hidden_dims,
            batch_size=batch_size,
            epochs=epochs,
            learning_rate=learning_rate,
            early_stopping_patience=early_stopping_patience
        )
        
        # åˆ›å»ºå¯è§†åŒ–
        print("\nğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–...")
        create_robustness_visualizations(results_df)
        create_robustness_heatmap(results_df)
        
        # åˆ†æç»“æœ
        print("\nğŸ” åˆ†æç»“æœ...")
        robustness_df = analyze_robustness_results(results_df)
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“„ ç”ŸæˆæŠ¥å‘Š...")
        report_file = generate_robustness_report(results_df, robustness_df)
        
        print("\n" + "=" * 60)
        print("ğŸ‰ å¿«é€Ÿæµ‹è¯•å®Œæˆï¼")
        print("=" * 60)
        print("ğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"  â€¢ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        print("  â€¢ é²æ£’æ€§æ›²çº¿: results/caac_outlier_robustness_curves.png")
        print("  â€¢ é²æ£’æ€§çƒ­åŠ›å›¾: results/caac_outlier_robustness_heatmap.png")
        
        # æ˜¾ç¤ºå…³é”®å‘ç°
        print("\nğŸ” å…³é”®å‘ç°é¢„è§ˆ:")
        print(f"  â€¢ æœ€é²æ£’æ–¹æ³•: {robustness_df.iloc[0]['Method']}")
        print(f"  â€¢ é²æ£’æ€§å¾—åˆ†: {robustness_df.iloc[0]['Overall_Robustness']:.4f}")
        print(f"  â€¢ æ€§èƒ½è¡°å‡: {robustness_df.iloc[0]['Performance_Drop']:.1f}%")
        
        print(f"\nğŸ’¡ è¿™æ˜¯åŸºäº{total_samples:,}æ ·æœ¬çš„å¿«é€ŸéªŒè¯ç»“æœ")
        print("   å¦‚éœ€æ›´å¯é çš„ç»“è®ºï¼Œè¯·è¿è¡Œæ ‡å‡†æµ‹è¯•: python run_standard_robustness_test.py")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """å‘½ä»¤è¡Œæ¥å£"""
    parser = argparse.ArgumentParser(description='CAACé²æ£’æ€§å‚æ•°åŒ–å¿«é€Ÿæµ‹è¯•')
    
    # å™ªå£°æ°´å¹³å‚æ•°ï¼ˆå¿«é€Ÿæµ‹è¯•é»˜è®¤å€¼ï¼‰
    parser.add_argument('--noise-levels', nargs='+', type=float, 
                       default=[0.0, 0.10, 0.20],
                       help='å™ªå£°æ°´å¹³åˆ—è¡¨ (é»˜è®¤: 0.0 0.10 0.20)')
    
    # ç½‘ç»œç»“æ„å‚æ•°
    parser.add_argument('--representation-dim', type=int, default=128,
                       help='è¡¨å¾ç»´åº¦ (é»˜è®¤: 128)')
    parser.add_argument('--feature-hidden-dims', nargs='+', type=int, default=[64],
                       help='ç‰¹å¾ç½‘ç»œéšè—å±‚ç»´åº¦ (é»˜è®¤: 64)')
    parser.add_argument('--abduction-hidden-dims', nargs='+', type=int, default=[128, 64],
                       help='æ¨æ–­ç½‘ç»œéšè—å±‚ç»´åº¦ (é»˜è®¤: 128 64)')
    
    # è®­ç»ƒå‚æ•°ï¼ˆå¿«é€Ÿæµ‹è¯•é…ç½®ï¼‰
    parser.add_argument('--batch-size', type=int, default=64,
                       help='æ‰¹é‡å¤§å° (é»˜è®¤: 64)')
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•° (é»˜è®¤: 100)')
    parser.add_argument('--learning-rate', type=float, default=0.001,
                       help='å­¦ä¹ ç‡ (é»˜è®¤: 0.001)')
    parser.add_argument('--early-stopping-patience', type=int, default=10,
                       help='æ—©åœè€å¿ƒå€¼ (é»˜è®¤: 10)')
    
    # æ•°æ®é›†é€‰æ‹©ï¼ˆå¿«é€Ÿæµ‹è¯•é…ç½®ï¼‰
    parser.add_argument('--datasets', nargs='+', 
                       default=['iris', 'wine', 'breast_cancer', 'optical_digits'],
                       help='æ•°æ®é›†åˆ—è¡¨ (é»˜è®¤: ä½¿ç”¨å°è§„æ¨¡æ•°æ®é›†)')
    
    args = parser.parse_args()
    
    # éªŒè¯å‚æ•°
    for noise in args.noise_levels:
        if not (0.0 <= noise <= 1.0):
            print(f"âŒ é”™è¯¯: å™ªå£°æ°´å¹³ {noise} å¿…é¡»åœ¨ [0.0, 1.0] èŒƒå›´å†…")
            sys.exit(1)
    
    if args.representation_dim <= 0:
        print("âŒ é”™è¯¯: è¡¨å¾ç»´åº¦å¿…é¡»ä¸ºæ­£æ•´æ•°")
        sys.exit(1)
    
    if any(dim <= 0 for dim in args.feature_hidden_dims):
        print("âŒ é”™è¯¯: ç‰¹å¾ç½‘ç»œéšè—å±‚ç»´åº¦å¿…é¡»ä¸ºæ­£æ•´æ•°")
        sys.exit(1)
    
    if any(dim <= 0 for dim in args.abduction_hidden_dims):
        print("âŒ é”™è¯¯: æ¨æ–­ç½‘ç»œéšè—å±‚ç»´åº¦å¿…é¡»ä¸ºæ­£æ•´æ•°")
        sys.exit(1)
    
    print("ğŸ¯ å¿«é€Ÿæµ‹è¯•ä½¿ç”¨å‚æ•°:")
    print(f"  â€¢ å™ªå£°æ°´å¹³: {args.noise_levels}")
    print(f"  â€¢ è¡¨å¾ç»´åº¦: {args.representation_dim}")
    print(f"  â€¢ ç‰¹å¾ç½‘ç»œéšè—å±‚: {args.feature_hidden_dims}")
    print(f"  â€¢ æ¨æ–­ç½‘ç»œéšè—å±‚: {args.abduction_hidden_dims}")
    print(f"  â€¢ æ‰¹é‡å¤§å°: {args.batch_size}")
    print(f"  â€¢ è®­ç»ƒè½®æ•°: {args.epochs}")
    print(f"  â€¢ å­¦ä¹ ç‡: {args.learning_rate}")
    print(f"  â€¢ æ—©åœè€å¿ƒå€¼: {args.early_stopping_patience}")
    print(f"  â€¢ æ•°æ®é›†: {args.datasets}")
    print()
    
    success = run_quick_robustness_test(
        noise_levels=args.noise_levels,
        representation_dim=args.representation_dim,
        feature_hidden_dims=args.feature_hidden_dims,
        abduction_hidden_dims=args.abduction_hidden_dims,
        batch_size=args.batch_size,
        epochs=args.epochs,
        learning_rate=args.learning_rate,
        early_stopping_patience=args.early_stopping_patience,
        datasets=args.datasets
    )
    
    if not success:
        print("\nğŸ’¡ å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥:")
        print("  1. æ˜¯å¦åœ¨æ­£ç¡®çš„condaç¯å¢ƒ (conda activate base)")
        print("  2. æ˜¯å¦å®‰è£…äº†æ‰€æœ‰ä¾èµ–åŒ…")
        print("  3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ (ç”¨äºä¸‹è½½æŸäº›æ•°æ®é›†)")
        print("  4. å‚æ•°è®¾ç½®æ˜¯å¦åˆç†")
        sys.exit(1)


if __name__ == "__main__":
    # å¦‚æœæ²¡æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°è¿è¡Œ
    if len(sys.argv) == 1:
        print("ğŸš€ ä½¿ç”¨å¿«é€Ÿæµ‹è¯•é»˜è®¤å‚æ•°è¿è¡Œ...")
        success = run_quick_robustness_test()
        if not success:
            print("\nğŸ’¡ å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥:")
            print("  1. æ˜¯å¦åœ¨æ­£ç¡®çš„condaç¯å¢ƒ (conda activate base)")
            print("  2. æ˜¯å¦å®‰è£…äº†æ‰€æœ‰ä¾èµ–åŒ…")
            print("  3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ (ç”¨äºä¸‹è½½æŸäº›æ•°æ®é›†)")
            sys.exit(1)
    else:
        main() 